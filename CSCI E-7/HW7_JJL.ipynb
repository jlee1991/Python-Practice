{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Homework 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first step is to load a data set from the sklearn website\n",
    "# https://scikit-learn.org/stable/datasets/index.html\n",
    "\n",
    "#For biological related datasets, I chose the diabetes dataset!\n",
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "# a series is a one dimensional array that can have any one datatype, string, floating point, integer, or even objects etc. \n",
    "\n",
    "# a dataframe is a two dimensional array that can have any number of one column data types\n",
    "# you can think of it like a spreadsheet or a dictionary of series \n",
    "\n",
    "#creates a data frame with our breast cancer data using the feature names as column labels\n",
    "x = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "print(list(data.feature_names))\n",
    "\n",
    "# creates a series with target data\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.092695</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.040696</td>\n",
       "      <td>-0.019442</td>\n",
       "      <td>-0.068991</td>\n",
       "      <td>-0.079288</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.041180</td>\n",
       "      <td>-0.096346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.047163</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>-0.040096</td>\n",
       "      <td>-0.024800</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>0.090620</td>\n",
       "      <td>0.108914</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>-0.035817</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.070900</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>-0.033214</td>\n",
       "      <td>-0.012577</td>\n",
       "      <td>-0.034508</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.067736</td>\n",
       "      <td>-0.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.096328</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.083808</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>-0.103389</td>\n",
       "      <td>-0.090561</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.034215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.033214</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>-0.065491</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>-0.096433</td>\n",
       "      <td>-0.059067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016281</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.028840</td>\n",
       "      <td>-0.009113</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>0.044958</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.030751</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>-0.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.045341</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.025607</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.081775</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.075636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.018062</td>\n",
       "      <td>0.080401</td>\n",
       "      <td>0.089244</td>\n",
       "      <td>0.107662</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.049415</td>\n",
       "      <td>0.024574</td>\n",
       "      <td>-0.023861</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.027917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070769</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.012117</td>\n",
       "      <td>0.056301</td>\n",
       "      <td>0.034206</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.038207</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.010517</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.019476</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.018062</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>-0.011335</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.008944</td>\n",
       "      <td>-0.054925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0   0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1  -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2   0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3  -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4   0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "5  -0.092695 -0.044642 -0.040696 -0.019442 -0.068991 -0.079288  0.041277   \n",
       "6  -0.045472  0.050680 -0.047163 -0.015999 -0.040096 -0.024800  0.000779   \n",
       "7   0.063504  0.050680 -0.001895  0.066630  0.090620  0.108914  0.022869   \n",
       "8   0.041708  0.050680  0.061696 -0.040099 -0.013953  0.006202 -0.028674   \n",
       "9  -0.070900 -0.044642  0.039062 -0.033214 -0.012577 -0.034508 -0.024993   \n",
       "10 -0.096328 -0.044642 -0.083808  0.008101 -0.103389 -0.090561 -0.013948   \n",
       "11  0.027178  0.050680  0.017506 -0.033214 -0.007073  0.045972 -0.065491   \n",
       "12  0.016281 -0.044642 -0.028840 -0.009113 -0.004321 -0.009769  0.044958   \n",
       "13  0.005383  0.050680 -0.001895  0.008101 -0.004321 -0.015719 -0.002903   \n",
       "14  0.045341 -0.044642 -0.025607 -0.012556  0.017694 -0.000061  0.081775   \n",
       "15 -0.052738  0.050680 -0.018062  0.080401  0.089244  0.107662 -0.039719   \n",
       "16 -0.005515 -0.044642  0.042296  0.049415  0.024574 -0.023861  0.074412   \n",
       "17  0.070769  0.050680  0.012117  0.056301  0.034206  0.049416 -0.039719   \n",
       "18 -0.038207 -0.044642 -0.010517 -0.036656 -0.037344 -0.019476 -0.028674   \n",
       "19 -0.027310 -0.044642 -0.018062 -0.040099 -0.002945 -0.011335  0.037595   \n",
       "\n",
       "          s4        s5        s6  \n",
       "0  -0.002592  0.019908 -0.017646  \n",
       "1  -0.039493 -0.068330 -0.092204  \n",
       "2  -0.002592  0.002864 -0.025930  \n",
       "3   0.034309  0.022692 -0.009362  \n",
       "4  -0.002592 -0.031991 -0.046641  \n",
       "5  -0.076395 -0.041180 -0.096346  \n",
       "6  -0.039493 -0.062913 -0.038357  \n",
       "7   0.017703 -0.035817  0.003064  \n",
       "8  -0.002592 -0.014956  0.011349  \n",
       "9  -0.002592  0.067736 -0.013504  \n",
       "10 -0.076395 -0.062913 -0.034215  \n",
       "11  0.071210 -0.096433 -0.059067  \n",
       "12 -0.039493 -0.030751 -0.042499  \n",
       "13 -0.002592  0.038393 -0.013504  \n",
       "14 -0.039493 -0.031991 -0.075636  \n",
       "15  0.108111  0.036056 -0.042499  \n",
       "16 -0.039493  0.052280  0.027917  \n",
       "17  0.034309  0.027368 -0.001078  \n",
       "18 -0.002592 -0.018118 -0.017646  \n",
       "19 -0.039493 -0.008944 -0.054925  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame.head() returns the first N rows (default is 5 if no parameter is passed in)\n",
    "x.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     151.0\n",
       "1      75.0\n",
       "2     141.0\n",
       "3     206.0\n",
       "4     135.0\n",
       "5      97.0\n",
       "6     138.0\n",
       "7      63.0\n",
       "8     110.0\n",
       "9     310.0\n",
       "10    101.0\n",
       "11     69.0\n",
       "12    179.0\n",
       "13    185.0\n",
       "14    118.0\n",
       "15    171.0\n",
       "16    166.0\n",
       "17    144.0\n",
       "18     97.0\n",
       "19    168.0\n",
       "20     68.0\n",
       "21     49.0\n",
       "22     68.0\n",
       "23    245.0\n",
       "24    184.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly Series.head() returns the first N rows as well \n",
    "y.head(25)\n",
    "\n",
    "# the meaning behind the target data\n",
    "#print(data.target_names) \n",
    "#data.target_names is not recognized for diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     151.0\n",
       "1      75.0\n",
       "2     141.0\n",
       "3     206.0\n",
       "4     135.0\n",
       "5      97.0\n",
       "6     138.0\n",
       "7      63.0\n",
       "8     110.0\n",
       "9     310.0\n",
       "10    101.0\n",
       "11     69.0\n",
       "12    179.0\n",
       "13    185.0\n",
       "14    118.0\n",
       "15    171.0\n",
       "16    166.0\n",
       "17    144.0\n",
       "18     97.0\n",
       "19    168.0\n",
       "20     68.0\n",
       "21     49.0\n",
       "22     68.0\n",
       "23    245.0\n",
       "24    184.0\n",
       "25    202.0\n",
       "26    137.0\n",
       "27     85.0\n",
       "28    131.0\n",
       "29    283.0\n",
       "30    129.0\n",
       "31     59.0\n",
       "32    341.0\n",
       "33     87.0\n",
       "34     65.0\n",
       "35    102.0\n",
       "36    265.0\n",
       "37    276.0\n",
       "38    252.0\n",
       "39     90.0\n",
       "40    100.0\n",
       "41     55.0\n",
       "42     61.0\n",
       "43     92.0\n",
       "44    259.0\n",
       "45     53.0\n",
       "46    190.0\n",
       "47    142.0\n",
       "48     75.0\n",
       "49    142.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 418 ms, sys: 77.5 ms, total: 495 ms\n",
      "Wall time: 5.47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# creates a dictionary, used to create parameters for Random forest regresssor \n",
    "param_grid = dict(\n",
    "    max_features=np.arange(2,8),\n",
    "    max_depth=[2,4],\n",
    "    min_samples_split=[5, 10, 15, 20],\n",
    ")    \n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=10)\n",
    "# exhaustive search over specified parameter svalues for an estimator\n",
    "gs = GridSearchCV(rfc, param_grid, cv=5, n_jobs=-1)\n",
    "# fits the data to the target\n",
    "gs.fit(x.values, y.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': array([2, 3, 4, 5, 6, 7]), 'max_depth': [2, 4], 'min_samples_split': [5, 10, 15, 20]}\n",
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(param_grid) # prints the dictionary\n",
    "print(param_grid['max_depth']) # accesses value at key 'max_depth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jlee/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "scores = gs.cv_results_ # creates a dictionary of the results\n",
    "\n",
    "sc = pd.DataFrame(scores) # put it in a panda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 2, 'min_sampl...</td>\n",
       "      <td>0.280512</td>\n",
       "      <td>0.427268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359553</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>45</td>\n",
       "      <td>0.466256</td>\n",
       "      <td>0.415561</td>\n",
       "      <td>0.384947</td>\n",
       "      <td>0.444706</td>\n",
       "      <td>0.399325</td>\n",
       "      <td>0.422159</td>\n",
       "      <td>0.029674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015204</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 2, 'min_sampl...</td>\n",
       "      <td>0.237686</td>\n",
       "      <td>0.393364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344942</td>\n",
       "      <td>0.062947</td>\n",
       "      <td>47</td>\n",
       "      <td>0.476668</td>\n",
       "      <td>0.422810</td>\n",
       "      <td>0.438178</td>\n",
       "      <td>0.425376</td>\n",
       "      <td>0.438642</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.019280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 2, 'min_sampl...</td>\n",
       "      <td>0.240160</td>\n",
       "      <td>0.392514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360655</td>\n",
       "      <td>0.062889</td>\n",
       "      <td>44</td>\n",
       "      <td>0.434552</td>\n",
       "      <td>0.401385</td>\n",
       "      <td>0.445882</td>\n",
       "      <td>0.448612</td>\n",
       "      <td>0.408239</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.019422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 2, 'min_sampl...</td>\n",
       "      <td>0.158021</td>\n",
       "      <td>0.399634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328179</td>\n",
       "      <td>0.087303</td>\n",
       "      <td>48</td>\n",
       "      <td>0.448461</td>\n",
       "      <td>0.424330</td>\n",
       "      <td>0.437304</td>\n",
       "      <td>0.442166</td>\n",
       "      <td>0.403209</td>\n",
       "      <td>0.431094</td>\n",
       "      <td>0.016038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 3, 'min_sampl...</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.424760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357820</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>46</td>\n",
       "      <td>0.465522</td>\n",
       "      <td>0.426167</td>\n",
       "      <td>0.482457</td>\n",
       "      <td>0.474536</td>\n",
       "      <td>0.431311</td>\n",
       "      <td>0.455999</td>\n",
       "      <td>0.022951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020184</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 3, 'min_sampl...</td>\n",
       "      <td>0.309092</td>\n",
       "      <td>0.435231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397909</td>\n",
       "      <td>0.048143</td>\n",
       "      <td>35</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>0.443612</td>\n",
       "      <td>0.466708</td>\n",
       "      <td>0.501526</td>\n",
       "      <td>0.454821</td>\n",
       "      <td>0.463398</td>\n",
       "      <td>0.020498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020123</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 3, 'min_sampl...</td>\n",
       "      <td>0.309545</td>\n",
       "      <td>0.418055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392387</td>\n",
       "      <td>0.051149</td>\n",
       "      <td>40</td>\n",
       "      <td>0.474973</td>\n",
       "      <td>0.414829</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.496233</td>\n",
       "      <td>0.447949</td>\n",
       "      <td>0.462025</td>\n",
       "      <td>0.028152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 3, 'min_sampl...</td>\n",
       "      <td>0.320438</td>\n",
       "      <td>0.421928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387538</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>41</td>\n",
       "      <td>0.498398</td>\n",
       "      <td>0.421847</td>\n",
       "      <td>0.444926</td>\n",
       "      <td>0.488162</td>\n",
       "      <td>0.451938</td>\n",
       "      <td>0.461054</td>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 4, 'min_sampl...</td>\n",
       "      <td>0.285949</td>\n",
       "      <td>0.446186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385466</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>43</td>\n",
       "      <td>0.487530</td>\n",
       "      <td>0.451394</td>\n",
       "      <td>0.486131</td>\n",
       "      <td>0.489723</td>\n",
       "      <td>0.447847</td>\n",
       "      <td>0.472525</td>\n",
       "      <td>0.018770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 4, 'min_sampl...</td>\n",
       "      <td>0.301253</td>\n",
       "      <td>0.470834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410275</td>\n",
       "      <td>0.063794</td>\n",
       "      <td>24</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.475642</td>\n",
       "      <td>0.447620</td>\n",
       "      <td>0.493501</td>\n",
       "      <td>0.464150</td>\n",
       "      <td>0.475502</td>\n",
       "      <td>0.018305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.015374      0.000988         0.002193        0.000084   \n",
       "1       0.015204      0.003334         0.001925        0.000109   \n",
       "2       0.014603      0.002364         0.001974        0.000089   \n",
       "3       0.015222      0.003675         0.002488        0.000951   \n",
       "4       0.019148      0.003743         0.002460        0.000453   \n",
       "5       0.020184      0.006570         0.003723        0.001486   \n",
       "6       0.020123      0.004155         0.002224        0.000654   \n",
       "7       0.020707      0.006505         0.003125        0.001712   \n",
       "8       0.018572      0.004632         0.002658        0.000685   \n",
       "9       0.033400      0.016531         0.002074        0.000330   \n",
       "\n",
       "  param_max_depth param_max_features param_min_samples_split  \\\n",
       "0               2                  2                       5   \n",
       "1               2                  2                      10   \n",
       "2               2                  2                      15   \n",
       "3               2                  2                      20   \n",
       "4               2                  3                       5   \n",
       "5               2                  3                      10   \n",
       "6               2                  3                      15   \n",
       "7               2                  3                      20   \n",
       "8               2                  4                       5   \n",
       "9               2                  4                      10   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'max_depth': 2, 'max_features': 2, 'min_sampl...           0.280512   \n",
       "1  {'max_depth': 2, 'max_features': 2, 'min_sampl...           0.237686   \n",
       "2  {'max_depth': 2, 'max_features': 2, 'min_sampl...           0.240160   \n",
       "3  {'max_depth': 2, 'max_features': 2, 'min_sampl...           0.158021   \n",
       "4  {'max_depth': 2, 'max_features': 3, 'min_sampl...           0.229500   \n",
       "5  {'max_depth': 2, 'max_features': 3, 'min_sampl...           0.309092   \n",
       "6  {'max_depth': 2, 'max_features': 3, 'min_sampl...           0.309545   \n",
       "7  {'max_depth': 2, 'max_features': 3, 'min_sampl...           0.320438   \n",
       "8  {'max_depth': 2, 'max_features': 4, 'min_sampl...           0.285949   \n",
       "9  {'max_depth': 2, 'max_features': 4, 'min_sampl...           0.301253   \n",
       "\n",
       "   split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "0           0.427268       ...                0.359553        0.049699   \n",
       "1           0.393364       ...                0.344942        0.062947   \n",
       "2           0.392514       ...                0.360655        0.062889   \n",
       "3           0.399634       ...                0.328179        0.087303   \n",
       "4           0.424760       ...                0.357820        0.072682   \n",
       "5           0.435231       ...                0.397909        0.048143   \n",
       "6           0.418055       ...                0.392387        0.051149   \n",
       "7           0.421928       ...                0.387538        0.035077   \n",
       "8           0.446186       ...                0.385466        0.061880   \n",
       "9           0.470834       ...                0.410275        0.063794   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               45            0.466256            0.415561   \n",
       "1               47            0.476668            0.422810   \n",
       "2               44            0.434552            0.401385   \n",
       "3               48            0.448461            0.424330   \n",
       "4               46            0.465522            0.426167   \n",
       "5               35            0.450322            0.443612   \n",
       "6               40            0.474973            0.414829   \n",
       "7               41            0.498398            0.421847   \n",
       "8               43            0.487530            0.451394   \n",
       "9               24            0.496599            0.475642   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.384947            0.444706            0.399325   \n",
       "1            0.438178            0.425376            0.438642   \n",
       "2            0.445882            0.448612            0.408239   \n",
       "3            0.437304            0.442166            0.403209   \n",
       "4            0.482457            0.474536            0.431311   \n",
       "5            0.466708            0.501526            0.454821   \n",
       "6            0.476140            0.496233            0.447949   \n",
       "7            0.444926            0.488162            0.451938   \n",
       "8            0.486131            0.489723            0.447847   \n",
       "9            0.447620            0.493501            0.464150   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.422159         0.029674  \n",
       "1          0.440335         0.019280  \n",
       "2          0.427734         0.019422  \n",
       "3          0.431094         0.016038  \n",
       "4          0.455999         0.022951  \n",
       "5          0.463398         0.020498  \n",
       "6          0.462025         0.028152  \n",
       "7          0.461054         0.028319  \n",
       "8          0.472525         0.018770  \n",
       "9          0.475502         0.018305  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.head(10) # view the panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1b9af9e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a series with column of best estimator feature importances\n",
    "be = pd.Series(gs.best_estimator_.feature_importances_,index=x.columns)\n",
    "\n",
    "# sort the series \n",
    "be_sorted = be.sort_values()\n",
    "\n",
    "# plot the sorted series\n",
    "be_sorted.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, s5 has the greatest impact on diabetes. This follows very closely by BMI. BP is third in order of importance but is nearly a third of s5 and BMI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
